{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "def get_data(filepath):\n",
    "    x_raw, y_raw = [], []\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            line = [float(x) for x in line.strip().split(' ')]\n",
    "            x_raw += [line[:-1]]\n",
    "            y_raw += [line[-1]]\n",
    "        \n",
    "        return np.array(x_raw), np.array(y_raw)\n",
    "    \n",
    "def shuffle(x, y):\n",
    "    \n",
    "    length = len(x)\n",
    "    indice = np.arange(length)\n",
    "    \n",
    "    np.random.shuffle(indice)\n",
    "        \n",
    "    return np.array([x[i] for i in indice]),  np.array([y[i] for i in indice])\n",
    "\n",
    "def split(x, y, split_ratio=2/3):\n",
    "    \n",
    "    train_len = math.ceil(len(x) * split_ratio)\n",
    "    return x[:train_len], y[:train_len], x[train_len:], y[train_len:]\n",
    "\n",
    "def plot_dataset(x, y):\n",
    "    \n",
    "    colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "    x = pd.DataFrame(x)\n",
    "    classes = np.unique(y)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    for i, c in enumerate(classes):\n",
    "        plt.scatter(x[y == c][0], x[y == c][1], label='Class {}'.format(c), c=colors[i])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# distance function\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.linalg.norm(x1 - x2, ord=2)\n",
    "    \n",
    "def time_constant(iteration, constant):\n",
    "    # iteration: 迭代總次數\n",
    "    # constant: 常數。這裡可以是有效寬度(sigma)初始值、學習率(leraning_rate)初始值\n",
    "    return iteration / np.log(constant)\n",
    "\n",
    "# 計算得勝類神經元 j* 的鄰近區域函數的強度\n",
    "# 高斯型式之鄰近區域函數\n",
    "def gaussian(d, sigma):\n",
    "    # d: 得勝神經元 j* 與 類神經元 j 的側向連結距離\n",
    "    # sigma: 有效寬度\n",
    "    return np.exp(-1 * d**2 / (2 * sigma**2))\n",
    "    \n",
    "# 指數衰減函數\n",
    "def exponential_decay(init, n, tau):\n",
    "    # init: 欲衰減參數的初始值。ex: 有效寬度(sigma)初始值、學習率(leraning_rate)初始值\n",
    "    # n: 第 n 次迭代數\n",
    "    # tau: 時間常數\n",
    "\n",
    "    return init * np.exp(-1 * n / tau)\n",
    "\n",
    "def learning_rate_decay(n):\n",
    "    return 0.9 * (1 - n/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "class SOM:\n",
    "    def __init__(self, row, col, input_dim, distance_func, kernel_func, sigma_decay_func, lr_decay_func):\n",
    "        \n",
    "        self.row = row\n",
    "        self.col = col\n",
    "        self.input_dim = input_dim\n",
    "        self.neuron_map = []\n",
    "        \n",
    "        self.distance_function = distance_func\n",
    "        self.kernel_function = kernel_func\n",
    "        self.sigma_decay_function = sigma_decay_func\n",
    "        self.lr_decay_function = lr_decay_func\n",
    "        \n",
    "        self.init_neuron()\n",
    "        \n",
    "    \n",
    "    def init_neuron(self):\n",
    "        for i in range(self.row):\n",
    "            self.neuron_map.append([Node(self.input_dim) for j in range(self.col)])\n",
    "        \n",
    "    def train(self, x_train, y_train, epoch_size, learning_rate0, sigma0):\n",
    "        def get_winner(x):\n",
    "            # 回傳得勝類神經元的索引值(tuple), ex: (0, 1)\n",
    "            min_distance = self.distance_function(x, self.neuron_map[0][0].weight)\n",
    "            winner = (0, 0)\n",
    "            for r in range(self.row):\n",
    "                for c in range(self.col):\n",
    "                    distance = self.distance_function(x, self.neuron_map[r][c].weight)\n",
    "                    winner = (r, c) if distance < min_distance else winner\n",
    "                    min_distance = distance if distance < min_distance else min_distance\n",
    "            return winner\n",
    "        \n",
    "        def get_neighbors(winner, sigma):\n",
    "            # 回傳得勝神經元的鄰居(list), ex: [(0, 0), (0, 2)]\n",
    "            sigma = round(sigma)\n",
    "            row_lowerbound = np.clip(winner[0] - sigma, 0, self.row).astype(int)\n",
    "            row_upperbound = np.clip(winner[0] + sigma, 0, self.row).astype(int)\n",
    "            col_lowerbound = np.clip(winner[1] - sigma, 0, self.col).astype(int)\n",
    "            col_upperbound = np.clip(winner[1] + sigma, 0, self.col).astype(int)\n",
    "            \n",
    "            return [(r, c) for c in range(col_lowerbound, col_upperbound) for r in range(row_lowerbound, row_upperbound)]            \n",
    "            \n",
    "        def update_weights(x, winner, neighbors, sigma, learning_rate):\n",
    "            # 更新類神經元的權重\n",
    "            winner_node = self.neuron_map[winner[0]][winner[1]]\n",
    "            neighbors_nodes = [self.neuron_map[index[0]][index[1]] for index in neighbors]\n",
    "            for node in neighbors_nodes:\n",
    "                distance = self.distance_function(winner_node.weight, node.weight)\n",
    "                theta = self.kernel_function(distance, sigma)\n",
    "                node.update_weight(x, learning_rate, theta)\n",
    "        \n",
    "        sigma_tau = time_constant(epoch_size, sigma0)\n",
    "        for n in range(1, epoch_size+1):\n",
    "            sigma = self.sigma_decay_function(sigma0, n, sigma_tau)\n",
    "            learning_rate = self.lr_decay_function(n)\n",
    "            x_train, y_train = shuffle(x_train, y_train)\n",
    "            for x, y in zip(x_train, y_train):\n",
    "                winner = get_winner(x)\n",
    "                neighbors = get_neighbors(winner, sigma)\n",
    "                update_weights(x, winner, neighbors, sigma, learning_rate)\n",
    "                \n",
    "#             if n % 100 == 0:\n",
    "            print('Epoch {}, Learning_rate: {} Sigma: {}\\n'.format(n, learning_rate, sigma))\n",
    "            self.plot_neuron_map()\n",
    "            \n",
    "        print('Final Result, Learning_rate: {} Sigma: {}\\n'.format(n, learning_rate, sigma))\n",
    "        self.plot_neuron_map()\n",
    "            \n",
    "    def plot_neuron_map(self):\n",
    "        \n",
    "        colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "        neurons_weights = [neuron.weight for neuron in np.array(self.neuron_map).flatten()]\n",
    "        \n",
    "\n",
    "        for weight in neurons_weights:\n",
    "            plt.scatter(weight[0], weight[1])\n",
    "\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "            \n",
    "    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, input_dim):\n",
    "        self.weight = np.random.uniform(-1, 1, input_dim)\n",
    "        self.win_probability = 0\n",
    "    \n",
    "    def update_weight(self, input_vector, learning_rate, theta):\n",
    "        self.weight += learning_rate * theta * (input_vector - self.weight)\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw, y_raw = get_data('dataset/2ring.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_raw, y_raw = shuffle(x_raw, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = split(x_raw, y_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 3\n",
    "col = 3\n",
    "input_dim = len(x_train[0])\n",
    "epoch_size = 1000\n",
    "# learning_rate0 = 0.1\n",
    "sigma0 = max(row, col)\n",
    "distance_func = euclidean_distance\n",
    "kernel_func = gaussian\n",
    "sigma_decay_func = exponential_decay\n",
    "lr_decay_func = learning_rate_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SOM(row, col, input_dim, distance_func, kernel_func, sigma_decay_func, lr_decay_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(x_train, y_train, epoch_size, learning_rate0, sigma0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_neuron_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        print(model.neuron_map[i][j].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
