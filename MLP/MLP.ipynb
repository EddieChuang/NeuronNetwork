{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, filepath, delimiter):\n",
    "        self.filepath = filepath\n",
    "        self.delimiter = delimiter\n",
    "        self.from_categorical = {}  # '100': 0, '010': 1, '001': 2\n",
    "        self.to_categorical = {}    # 0: [1,0,0], 1: [0,1,0], 2: [0,0,1]\n",
    "    \n",
    "    def get_raw_data(self):\n",
    "        dataset = np.loadtxt(fname=self.filepath, delimiter=self.delimiter)\n",
    "        return dataset[:, :-1], dataset[:, -1]\n",
    "    \n",
    "    def get_data(self):\n",
    "        def normalize(x):\n",
    "            return (x - x.min(axis=0)) / (x.max(axis=0) - x.min(axis=0))\n",
    "            \n",
    "        def convert_to_categorical(hot, length):\n",
    "            return np.array([0 if not i == hot else 1 for i in range(length)])\n",
    "        \n",
    "        x_train, labels = self.get_raw_data()\n",
    "        \n",
    "        categories = np.sort(np.unique(labels))   \n",
    "        length = len(categories)\n",
    "        \n",
    "        for i in range(length):\n",
    "            categorical = convert_to_categorical(i, length)\n",
    "            self.from_categorical[''.join(map(str, categorical))] = categories[i]\n",
    "            self.to_categorical[categories[i]] = categorical\n",
    "            \n",
    "        y_train = list(map(lambda label: self.to_categorical[label], labels))\n",
    "\n",
    "        return normalize(x_train), np.array(y_train)\n",
    "    \n",
    "    def split_shuffle(self, x, y, ratio):\n",
    "        length = len(x) \n",
    "        len_train = int(round(length* ratio))\n",
    "        index = list(range(length))\n",
    "        random.shuffle(index)\n",
    "        x_train = [x[index[i]] for i in range(len_train)]\n",
    "        y_train = [y[index[i]] for i in range(len_train)]\n",
    "        x_test = [x[index[i]] for i in range(len_train, length)]\n",
    "        y_test = [y[index[i]] for i in range(len_train, length)]\n",
    "        \n",
    "        return np.array(x_train), np.array(y_train), np.array(x_test), np.array(y_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    def plot(self):\n",
    "        x, y = self.get_raw_data()\n",
    "        \n",
    "        pca = PCA(n_components=2)  # 2-dimensional PCA\n",
    "        x = pd.DataFrame(x)\n",
    "\n",
    "        \n",
    "        plt.xlabel('x')\n",
    "        plt.ylabel('y')\n",
    "        colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "        \n",
    "        classes = np.unique(y)\n",
    "        for i, c in enumerate(classes):\n",
    "            plt.scatter(x[y == c][0], x[y == c][1], label='Class {}'.format(c), c=colors[i])\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Model:\n",
    "    def __init__(self):\n",
    "        self.nodes = [] # 2d list\n",
    "        self.pseudo_root = Node(ndim=0, node_type='pseudo', activation_func=None, index=None, neuron_threshold=None)\n",
    "        self.nlayer = 0\n",
    "        \n",
    "    def add(self, ndim, num, activation_func, neuron_threshold):\n",
    "        \n",
    "        node_type = 'input' if self.nlayer == 0 else 'output'\n",
    "        newNodes = [Node(ndim, node_type, activation_func, index+1, neuron_threshold) for index in range(num)]\n",
    "        \n",
    "        # connect newNodes to last layer\n",
    "        layer = [] if self.nlayer == 0 else self.nodes[self.nlayer - 1]\n",
    "        for node in newNodes:\n",
    "            node.input_nodes = layer\n",
    "        \n",
    "        # connect last layer to newNodes\n",
    "        node_type = 'input' if self.nlayer == 1 else 'hidden'\n",
    "        for node in layer:\n",
    "            node.output_nodes = newNodes\n",
    "            node.type = node_type\n",
    "            \n",
    "        # modify pseudo root\n",
    "        self.pseudo_root.input_nodes = newNodes\n",
    "            \n",
    "        self.nodes.append(newNodes)\n",
    "        self.nlayer += 1\n",
    "        \n",
    "    def train(self, x, y_hat, learning_rate):\n",
    "        \n",
    "        output_layer = self.nodes[self.nlayer - 1]\n",
    "        Model.compute(self.pseudo_root, x)\n",
    "        Model.update(self.pseudo_root, x, y_hat, learning_rate)\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        def activate(vec):\n",
    "            one_hot = [0] * len(vec)\n",
    "            one_hot[np.argmax(vec)] = 1\n",
    "            return one_hot\n",
    "    \n",
    "        output_layer = self.nodes[self.nlayer - 1]\n",
    "        prediction = []\n",
    "        for x in x_test:\n",
    "            Model.compute(self.pseudo_root, x)\n",
    "            prediction.append(activate([node.value for node in output_layer]))\n",
    "            \n",
    "        return np.array(prediction)\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute(root, x):\n",
    "        def postorder(node):\n",
    "            for input_node in node.input_nodes:\n",
    "                if not input_node._id in visited:\n",
    "                    postorder(input_node)\n",
    "            node.compute(x)   \n",
    "            visited.append(node._id)\n",
    "        \n",
    "        visited = []\n",
    "        postorder(root)\n",
    "    \n",
    "    @staticmethod\n",
    "    def update(output_node, x, y_hat, learning_rate):\n",
    "        def preorder(root):\n",
    "            visited = []\n",
    "            queue = [node for node in root.input_nodes]\n",
    "            while queue != []:\n",
    "                front = queue.pop(0)\n",
    "                \n",
    "                queue += [node for node in front.input_nodes if not node._id in visited]\n",
    "                front.update_weight(x=x, y_hat=y_hat, learning_rate=learning_rate)\n",
    "                \n",
    "                visited += [node._id for node in front.input_nodes]\n",
    "        \n",
    "        preorder(output_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 0\n",
    "class Node:\n",
    "    def __init__(self, ndim, node_type, activation_func, index, neuron_threshold):\n",
    "        global ID\n",
    "        self._id = ID\n",
    "        self.index = index  # use for update_weight(...), start from 1, 0 is for neuron_threshold's weight\n",
    "        self.type = node_type # ['input', 'hidden', 'output', 'pseudo']\n",
    "        self.activation_func = activation_func\n",
    "        self.neuron_threshold = neuron_threshold\n",
    "        self.weight = np.random.random((ndim+1))\n",
    "        \n",
    "        self.value = 0\n",
    "        self.gradient = 0\n",
    "        self.input_nodes = []\n",
    "        self.output_nodes = []\n",
    "        ID += 1\n",
    "    \n",
    "    def get_input(self, values):\n",
    "        return np.concatenate((np.array([self.neuron_threshold]), values), axis=0)\n",
    "    \n",
    "    def compute(self, x=[]):\n",
    "        input_vec = []\n",
    "        if self.type == 'pseudo':\n",
    "            return\n",
    "        \n",
    "        if self.type == 'input':\n",
    "            input_vec = self.get_input(x)\n",
    "        else: # 'hidden', 'output'\n",
    "            input_vec = self.get_input([node.value for node in self.input_nodes])\n",
    "        \n",
    "        self.value = self.activation_func(np.dot(self.weight, input_vec))\n",
    "    \n",
    "    def update_weight(self, x, learning_rate, y_hat):\n",
    "        def get_gradient(y_hat):\n",
    "            if self.type == 'output':\n",
    "                return (y_hat[self.index-1] - self.value) * self.value * (1 - self.value)\n",
    "            else: # 'input', 'hidden'\n",
    "                output_grad = np.array([node.gradient for node in self.output_nodes])\n",
    "                output_weight = np.array([node.weight[self.index] for node in self.output_nodes])\n",
    "                return np.dot(output_grad, output_weight) * self.value * (1 - self.value)\n",
    "                \n",
    "        self.gradient = get_gradient(y_hat)\n",
    "        if self.type == 'input':\n",
    "            self.weight += learning_rate * self.gradient * self.get_input(x)\n",
    "        else:\n",
    "            self.weight += learning_rate * self.gradient * self.get_input([node.value for node in self.input_nodes])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_data(filepath):\n",
    "    dataset = np.loadtxt(fname=filepath, delimiter=delimiter)\n",
    "    threshold = np.array([[neuron_threshold]] * len(dataset))\n",
    "    return dataset[:, :-1], dataset[:, -1]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def plot_train(x_train, y_train):    \n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    for i in range(len(x_train)):\n",
    "        plt.plot(x_train[i, 0], x_train[i, 1], 'b*' if y_train[i]==0 else 'r*')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def precision(prediction, y_hat):\n",
    "    correct = 0\n",
    "    error = 0\n",
    "    for pred, y in zip(prediction, y_hat):\n",
    "        correct += 1 if np.array_equal(pred, y) else 0\n",
    "        error += 1 if not np.array_equal(pred, y) else 0\n",
    "    \n",
    "    return correct / len(y_hat)\n",
    "\n",
    "def fit(epoch, model, x_train, y_train, learning_rate):\n",
    "    for i in range(1, epoch + 1):\n",
    "        for x, y_hat in zip(x_train, y_train):\n",
    "            model.train(x, y_hat, learning_rate=learning_rate)\n",
    "        \n",
    "        print('Epoch {}: Accuracy: {}'.format(i+1, precision(model.predict(x_test), y_test)))\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epoch = 100\n",
    "dataset_dir = 'dataset/'\n",
    "neuron_threshold = -2\n",
    "learning_rate = 0.1\n",
    "dataset_files = ['IRIS.txt', 'wine.txt', 'xor.txt', 'C10D.txt', 'C3D.txt', '8OX.txt', '5CloseS1.txt', '4satellite-6.txt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(filepath=dataset_dir + dataset_files[0], delimiter=' ')\n",
    "x, y = dataset.get_data()\n",
    "x_train, y_train, x_test, y_test = dataset.split_shuffle(x, y, 2/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(x_train[0])\n",
    "output_dim = len(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.add(ndim=input_dim, num=3, activation_func=sigmoid, neuron_threshold=neuron_threshold)\n",
    "#     model.add(ndim=3, num=3, activation_func=sigmoid, neuron_threshold=neuron_threshold)\n",
    "#     model.add(ndim=3, num=3, activation_func=sigmoid, neuron_threshold=neuron_threshold)\n",
    "#     model.add(ndim=2, num=2, activation_func=sigmoid, neuron_threshold=neuron_threshold)\n",
    "model.add(ndim=3, num=output_dim, activation_func=sigmoid, neuron_threshold=neuron_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit(epoch, model, x_train, y_train, learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
